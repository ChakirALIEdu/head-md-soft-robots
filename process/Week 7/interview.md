# Podcast Structure

## Introduction
--> Start with the question: How do censorship algorithms and targeted content based on identities affect self-expression?--> Lay out the scope of the episode: we’ll look at hypotheses, experiences from our interviewees (Karim and Lise), and examples from articles to explore this.

## Hypotheses
- Censorship and filter algorithms decide what topics are amplified, and those decisions seem biased.
- Subjects suspect there might be human intervention involved in these algorithms, because the bias feels deliberate.
- There is significant bias when it comes to censorship, particularly affecting marginalized identities.

-  Is this bias intentional, or a byproduct of how the algorithm prioritizes content?

## Arguments 
Experiences of Karim and Lise

- Share their observations of biased or censored content, particularly on platforms like TikTok.

- Highlight their belief in TikTok’s “unbiased” nature despite its catered content that reinforces certain biases.

###   Behavioral Impact
-  Discuss how people self-censor to avoid triggering suppression by algorithms.

- Bring in examples from articles to back this up.

### Bias

- Algorithms prioritize engaging content, which may not include content from marginalized identities.

- Explore whether this is active censorship or a systemic issue in how algorithms evaluate content.

- Use articles and research to reinforce this argument.

# Quotes 

Incorporate direct quotes from Karim and Lise that illustrate their experiences and perspectives.

--> Add relevant excerpts from the articles to ground the discussion in broader trends.

# Conclusion

 Recap the main points: the role of algorithms in shaping what we see, how biases manifest, and the impact on self-expression.
 
 --> Leave the conclusion open-ended: the scope of this study is small, and the complexity of the issue means there’s no definitive answer yet.
 
 --> Encourage listeners to reflect on their own experiences with censorship and targeted content.




---------------------
#  


# Structure for the podcast


Introduce question: perception of censorship algorithms and the effect of censorship on self-expression? on targeted content based on identities?


--> different hypothesis
 --> Censorship and filter algorithms decide what topics get brought out most, and those topics are biased.
---> subjects suspect there may be human intervention involved in the algorithm, because of the bias
---> there is notable bias when it comes to the censorship, particularly targeting marginalised identities 
--> is it on purpose?

--> arguments 
---> recount events and experiences from both interviewees (Karim and Lise)
--->  biased information being brought out
---> bias in the way that they believe tiktok is "unbiased" despite being catered to them
--> self-censorship behaviour
---> articles as a source
--> is the biased content being brought out more because it engages people? and marginalised identities are censored as a whole not by active censorship but because of the nature of their identities?
---> quote articles

--> quotes

---> conclusion
--> open ended conclusion. case study too small and narrow to get an answer 
